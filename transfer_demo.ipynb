{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b31557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ca78e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_path = \"t5_styled_neutral/checkpoint-5964\"\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(checkpoint_path)\n",
    "tokenizer = T5Tokenizer.from_pretrained(checkpoint_path)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a414abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_neutral(model, tokenizer, styled_sentence, age_label):\n",
    "    prompt = f\"transfer from {age_label} to neutral style: {styled_sentence}\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(**inputs, max_length=64)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e1ac5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_2 = \"t5_neutral_styled/checkpoint-5964\"\n",
    "\n",
    "model_2 = T5ForConditionalGeneration.from_pretrained(checkpoint_path_2)\n",
    "tokenizer_2 = T5Tokenizer.from_pretrained(checkpoint_path_2)\n",
    "model_2 = model_2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b15c84bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_styled(model, tokenizer, neutral_sentence, age_label):\n",
    "    prompt = f\"transfer to {age_label} style: {neutral_sentence}\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(**inputs, max_length=64)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0037fe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "styled_input = \"I love my mommy so much.\"\n",
    "origin_age = \"Under12\"\n",
    "target_age = \"25-34\"\n",
    "#age selections: \"25-34\", \"18-24\", \"55-74\", \"35-44\", \"45-54\", \"75YearsOrOlder\", \"Under12\", \"12-17\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a7ac8418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love my mommy .\n"
     ]
    }
   ],
   "source": [
    "neutral_sentence = generate_neutral(model, tokenizer, styled_input, origin_age)\n",
    "print(neutral_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "68310d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mommy was so proud of her.\n"
     ]
    }
   ],
   "source": [
    "styled_sentence = generate_neutral(model_2, tokenizer_2, neutral_sentence, target_age)\n",
    "print(styled_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
